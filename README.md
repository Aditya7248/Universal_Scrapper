Here's a README template for your Universal Scrapper repository:

```markdown
# Universal Scrapper

## Overview
Universal Scrapper is a versatile web scraping tool built in Python that allows users to extract data from any website without the need for a predefined schema. This tool is designed to be user-friendly and adaptable, making it suitable for a wide range of data extraction tasks.

## Features
- **No Predefined Schema**: Scrape any website without needing a specific structure.
- **Multiple Output Formats**: Export scraped data in JSON, CSV, or Excel formats.
- **User-Friendly Interface**: Simple configuration for setting up and running scraping tasks.
- **Robust and Flexible**: Handles various website structures and layouts.

## Requirements
- Python 3.x
- Required libraries:
  - `requests`
  - `BeautifulSoup4`
  - `pandas`

## Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/Aditya7248/Universal_Scrapper.git
   ```
2. Navigate to the project directory:
   ```bash
   cd Universal_Scrapper
   ```
3. Install the required packages:
   ```bash
   pip install -r requirements.txt
   ```

## Usage
1. Run the scrapper script:
   ```bash
   python scrapper.py
   ```
2. Configure the parameters (target URL, output format, etc.) as prompted.

## Example
To scrape data from a website, simply input the URL when prompted. The scrapper will extract the data and save it in your desired format.

## Contributing
Contributions are welcome! Please feel free to submit a pull request or open an issue to discuss potential improvements.

## License
This project is licensed under the [MIT License](LICENSE).

```

Feel free to customize any sections, especially the contact information and license details!
